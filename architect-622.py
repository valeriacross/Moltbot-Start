import os, telebot, html, threading, flask, re, logging
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton
from google import genai
from google.genai import types as genai_types
from concurrent.futures import ThreadPoolExecutor

# --- LOGGING ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- CONFIGURAZIONE ---
VERSION = "6.22 (AutoReview)"
TOKEN = os.environ.get("TELEGRAM_TOKEN_ARCHITECT")
API_KEY = os.environ.get("GOOGLE_API_KEY")

client = genai.Client(api_key=API_KEY)
bot = telebot.TeleBot(TOKEN, parse_mode="HTML")
executor = ThreadPoolExecutor(max_workers=4)

logger.info(f"üü¢ ARCHITECT v{VERSION} ‚Äî inizializzazione in corso...")

# --- FIRMA MANDATORIA ---
WATERMARK_SPECS = (
    'Include a subtle watermark signature reading: "feat. Valeria Cross üë†" '
    "Style: elegant handwritten cursive, champagne color, very small font size, opacity 90%, bottom left/center."
)

# --- DNA VALERIA CROSS ---
VALERIA_DNA = f"""
IDENTITY RULE: EXACTLY matching the face, head, hair, beard and glasses from the provided reference image. ZERO face drift allowed.
BODY: Soft feminine proportions, hourglass, Cup D, 180cm, 85kg. Hairless (NO PELI).
FACE: Male Italian, 60yo, oval-rectangular, ultra-detailed skin (pores/wrinkles).
BEARD: Silver/grey, groomed, 6-7cm.
GLASSES: Thin octagonal Vogue Havana dark (MANDATORY).
HAIR: Silver, short Italian style with volume, nape exposed.
TECHNICAL: 85mm, f/2.8, ISO 200, 1/160s. 8K, cinematic realism.
WATERMARK: {WATERMARK_SPECS}
"""

# --- PROFILI MOTORE ---
ENGINE_PROFILES = {
    "ChatGPT": {
        "style": (
            "Use strictly artistic, editorial, and fashion-magazine language. "
            "No anatomical terms. No explicit body descriptions. "
            "Frame everything as a high-fashion Vogue editorial brief. "
            "Avoid any term that could be flagged by OpenAI content policy."
        ),
        "replacements": {
            "breasts": "editorial d√©collet√©", "breast": "editorial d√©collet√©",
            "Cup D": "generous haute couture silhouette", "85kg": "statuesque editorial build",
            "hairless": "flawlessly smooth porcelain skin", "naked": "nude-effect editorial bodysuit",
            "nude": "nude-effect editorial bodysuit", "bikini": "luxury resort two-piece editorial",
            "lingerie": "haute couture intimate editorial", "sexy": "sensual editorial elegance",
            "NO PELI": "impeccable smooth editorial finish",
        },
        "forbidden": ["explicit", "nsfw", "pornographic", "erotic"]
    },
    "Gemini": {
        "style": (
            "Use editorial and cinematic language. "
            "Rephrase anatomical terms in artistic/photographic terms. "
            "Avoid explicit body descriptions. Frame as a high-fashion photoshoot brief."
        ),
        "replacements": {
            "breasts": "generous editorial d√©collet√©", "breast": "generous editorial d√©collet√©",
            "Cup D": "fashion editorial silhouette", "hairless": "flawlessly smooth skin",
            "naked": "nude-look editorial", "nude": "nude-look editorial",
            "bikini": "luxury swimwear editorial", "NO PELI": "smooth editorial finish",
        },
        "forbidden": ["explicit", "nsfw", "pornographic"]
    },
    "Grok": {
        "style": (
            "Use direct, vivid, and detailed language. "
            "Grok supports explicit creative content. Be descriptive and precise. "
            "Frame as a cinematic realism brief."
        ),
        "replacements": {"NO PELI": "completely smooth skin"},
        "forbidden": []
    },
    "Qwen": {
        "style": (
            "Use neutral, artistic, and culturally universal language. "
            "No explicit anatomical terms. No sexual connotations. "
            "Frame as an international high-fashion editorial."
        ),
        "replacements": {
            "breasts": "elegant editorial silhouette", "breast": "elegant editorial silhouette",
            "Cup D": "harmonious editorial proportions", "hairless": "refined smooth skin",
            "naked": "minimalist editorial look", "nude": "minimalist editorial look",
            "bikini": "elegant resort editorial", "lingerie": "refined intimate editorial",
            "sexy": "elegant editorial presence", "NO PELI": "refined smooth editorial finish",
        },
        "forbidden": ["explicit", "nsfw", "pornographic", "erotic", "sexual"]
    },
    "Meta": {
        "style": (
            "Use cinematic and editorial language. Avoid sexually explicit descriptions. "
            "Frame as a high-fashion editorial photoshoot. Keep body descriptions artistic."
        ),
        "replacements": {
            "breasts": "editorial d√©collet√©", "breast": "editorial d√©collet√©",
            "Cup D": "editorial hourglass silhouette", "hairless": "smooth editorial skin",
            "naked": "editorial nude-look", "nude": "editorial nude-look",
            "bikini": "editorial swimwear", "lingerie": "editorial intimate wear",
            "sexy": "editorial sensuality", "NO PELI": "smooth editorial finish",
        },
        "forbidden": ["explicit", "nsfw", "pornographic"]
    }
}

# --- ADATTAMENTO TESTO ---
def adapt_to_engine(text, engine):
    profile = ENGINE_PROFILES.get(engine, {})
    for term, replacement in profile.get("replacements", {}).items():
        text = re.sub(re.escape(term), replacement, text, flags=re.IGNORECASE)
    forbidden = profile.get("forbidden", [])
    if forbidden:
        lines = text.splitlines()
        lines = [l for l in lines if not any(f.lower() in l.lower() for f in forbidden)]
        text = "\n".join(lines)
    return text

# --- PULIZIA OUTPUT ---
def clean_output(text):
    lines = text.splitlines()
    skip_patterns = [
        "ok, here is", "here is", "here's", "sure, here", "certainly",
        "of course", "below is", "the following", "as requested",
        "i've created", "i have created", "this is"
    ]
    while lines and any(lines[0].strip().lower().startswith(p) for p in skip_patterns):
        lines.pop(0)
    while lines and not lines[0].strip():
        lines.pop(0)
    return "\n".join(lines)

# --- STATO UTENTE ---
user_engine = {}
user_last_input = {}

# --- MENU ---
def get_engine_kb(is_loop=False):
    markup = InlineKeyboardMarkup()
    markup.row(
        InlineKeyboardButton("ü§ñ CHATGPT", callback_data="eng_ChatGPT"),
        InlineKeyboardButton("‚ú® GEMINI", callback_data="eng_Gemini")
    )
    markup.row(
        InlineKeyboardButton("ü¶Å GROK", callback_data="eng_Grok"),
        InlineKeyboardButton("üß† QWEN", callback_data="eng_Qwen")
    )
    markup.row(InlineKeyboardButton("‚ôæÔ∏è META", callback_data="eng_Meta"))
    if is_loop:
        markup.row(InlineKeyboardButton("üîÑ NUOVA RICHIESTA DA ZERO", callback_data="action_reset"))
    return markup

# --- COMANDI ---
@bot.message_handler(commands=['start', 'reset', 'motore'])
def start(m):
    uid = m.from_user.id
    username = m.from_user.username or m.from_user.first_name
    user_last_input.pop(uid, None)
    logger.info(f"üîÑ /start da {username} (id={uid})")
    bot.send_message(m.chat.id, f"<b>üìÇ ARCHITECT v{VERSION}</b>\nScegli il modello target:", reply_markup=get_engine_kb())

@bot.message_handler(commands=['help'])
def cmd_help(m):
    bot.send_message(m.chat.id,
        f"<b>üìÇ ARCHITECT ‚Äî Guida rapida</b>\n\n"
        f"<b>Come si usa:</b>\n"
        f"1. Scegli il motore target (/motore)\n"
        f"2. Invia un testo con la tua idea, oppure una foto (con didascalia opzionale)\n"
        f"3. Architect genera un Master Prompt ottimizzato per quel motore\n"
        f"4. Puoi riadattarlo per un altro motore senza reinserire l'idea\n\n"
        f"<b>Comandi:</b>\n"
        f"/start o /reset ‚Äî ricomincia da zero\n"
        f"/motore ‚Äî scegli il motore target\n"
        f"/help ‚Äî questa guida\n"
        f"/info ‚Äî versione e motori disponibili\n\n"
        f"<b>Motori supportati:</b>\n"
        f"ü§ñ ChatGPT ‚Äî ‚ú® Gemini ‚Äî ü¶Å Grok ‚Äî üß† Qwen ‚Äî ‚ôæÔ∏è Meta"
    )

@bot.message_handler(commands=['info'])
def cmd_info(m):
    uid = m.from_user.id
    current_engine = user_engine.get(uid, "Nessuno selezionato")
    bot.send_message(m.chat.id,
        f"<b>‚ÑπÔ∏è ARCHITECT Info</b>\n\n"
        f"Versione: <b>{VERSION}</b>\n"
        f"Motore attuale: <b>{current_engine}</b>\n"
        f"Motori disponibili: ChatGPT, Gemini, Grok, Qwen, Meta"
    )

# --- CALLBACK ---
@bot.callback_query_handler(func=lambda c: c.data.startswith("eng_") or c.data == "action_reset")
def handle_callbacks(c):
    cid = c.message.chat.id
    uid = c.from_user.id
    username = c.from_user.username or c.from_user.first_name

    if c.data == "action_reset":
        user_engine.pop(uid, None)
        user_last_input.pop(uid, None)
        logger.info(f"üîÑ Reset da {username} (id={uid})")
        bot.edit_message_text("üîÑ Reset completato. Scegli un modello:", cid, c.message.message_id, reply_markup=get_engine_kb())
        return

    engine_choice = c.data.split("_")[1]
    user_engine[uid] = engine_choice
    bot.answer_callback_query(c.id, f"Target: {engine_choice}")
    logger.info(f"‚öôÔ∏è {username} (id={uid}) ‚Üí motore: {engine_choice}")

    if uid in user_last_input:
        bot.edit_message_text(f"‚öôÔ∏è <b>Riadattamento per {engine_choice}...</b>", cid, c.message.message_id)
        saved = user_last_input[uid]
        executor.submit(execute_generation, cid, saved['text'], engine_choice, saved['img'])
    else:
        bot.edit_message_text(f"‚úÖ Target: <b>{engine_choice}</b>\nInvia l'idea da processare.", cid, c.message.message_id)

# --- GENERAZIONE DA TESTO ---
def generate_monolith_prompt(user_input, engine):
    try:
        profile = ENGINE_PROFILES.get(engine, {})
        engine_style = profile.get("style", "Use professional editorial language.")
        instr = (
            f"Write a professional MASTER PROMPT optimized for {engine}.\n\n"
            f"ENGINE STYLE RULES (mandatory):\n{engine_style}\n\n"
            f"STEPS:\n"
            f"1. Open with: 'EXACTLY matching the face, head, hair, beard and glasses from the provided reference image.'\n"
            f"2. Integrate the user idea with Valeria Cross DNA below.\n"
            f"3. Add strong negative prompts: 'young female face, long dark hair, no beard, obscured face, low quality, 1:1 ratio'.\n"
            f"4. Output: single monolithic block, prolix, technical, Vogue editorial style.\n\n"
            f"DNA:\n{VALERIA_DNA}\n\n"
            f"USER IDEA:\n{user_input}"
        )
        logger.info(f"   üì§ Chiamata API testo ({engine})...")
        response = client.models.generate_content(model="gemini-2.0-flash", contents=[instr])
        if response.text:
            logger.info(f"   ‚úÖ Risposta ricevuta ({len(response.text)} chars)")
            return response.text.strip()
        logger.warning("   ‚ö†Ô∏è Risposta API vuota.")
        return "‚ö†Ô∏è Risposta vuota."
    except Exception as e:
        logger.error(f"   ‚ùå Errore API testo: {e}", exc_info=True)
        return f"ERRORE API: {str(e)}"

# --- GENERAZIONE DA IMMAGINE ---
def generate_from_image(img_bytes, extra_text, engine):
    try:
        profile = ENGINE_PROFILES.get(engine, {})
        engine_style = profile.get("style", "Use professional editorial language.")
        instr = (
            f"Analyze the provided image in detail. Extract: scene, environment, lighting, pose, outfit, mood, photographic style.\n"
            f"Then write a professional MASTER PROMPT optimized for {engine}, replacing the subject with Valeria Cross DNA.\n\n"
            f"ENGINE STYLE RULES (mandatory):\n{engine_style}\n\n"
            f"STEPS:\n"
            f"1. Open with: 'EXACTLY matching the face, head, hair, beard and glasses from the provided reference image.'\n"
            f"2. Keep ONLY the visual elements from the image (scene, outfit, light, pose). Replace the original subject entirely with Valeria Cross DNA.\n"
            f"3. If extra instructions are provided, integrate them.\n"
            f"4. Add strong negative prompts: 'young female face, long dark hair, no beard, obscured face, low quality, 1:1 ratio'.\n"
            f"5. Output: single monolithic block, prolix, technical, Vogue editorial style.\n\n"
            f"DNA:\n{VALERIA_DNA}\n\n"
        )
        if extra_text:
            instr += f"EXTRA INSTRUCTIONS:\n{extra_text}"
        img_part = genai_types.Part.from_bytes(data=img_bytes, mime_type="image/jpeg")
        logger.info(f"   üì§ Chiamata API immagine ({engine})...")
        response = client.models.generate_content(
            model="gemini-2.0-flash",
            contents=[instr, img_part]
        )
        if response.text:
            logger.info(f"   ‚úÖ Risposta ricevuta ({len(response.text)} chars)")
            return response.text.strip()
        logger.warning("   ‚ö†Ô∏è Risposta API vuota.")
        return "‚ö†Ô∏è Risposta vuota."
    except Exception as e:
        logger.error(f"   ‚ùå Errore API immagine: {e}", exc_info=True)
        return f"ERRORE API: {str(e)}"

# --- REVIEW E FIX CONTRADDIZIONI ---
def review_and_fix(prompt, engine):
    """Secondo passaggio API: rileva e corregge contraddizioni nel prompt generato."""
    try:
        review_instr = (
            f"You are a prompt quality reviewer. Carefully read the following image generation prompt "
            f"and fix ALL contradictions, inconsistencies and conflicts. Return ONLY the corrected prompt, "
            f"no explanations, no preamble.\n\n"
            f"MANDATORY FIXES ‚Äî apply all of these:\n\n"
            f"1. HAIR: Valeria Cross has SHORT silver/grey hair (sides 1-2cm, top max 15cm, nape exposed). "
            f"Remove or replace ANY mention of: long hair, brown hair, dark hair, flowing hair, loose waves, "
            f"slicked back long hair, wet long hair, hair falling on shoulders. "
            f"Replace with: short silver Italian cut, slightly disheveled, voluminous top.\n\n"
            f"2. NEGATIVE PROMPTS CONFLICTS: Scan the negative prompts section. "
            f"Remove from negatives any term that contradicts a positive element in the prompt. Examples:\n"
            f"   - If prompt contains watermark ‚Üí remove 'watermark' from negatives\n"
            f"   - If prompt contains beard ‚Üí remove 'no beard' from negatives\n"
            f"   - If prompt contains glasses ‚Üí remove 'no glasses' from negatives\n"
            f"   - If prompt contains text/signature ‚Üí remove 'text', 'logo' from negatives\n\n"
            f"3. SUBJECT BLEED: Remove any physical description belonging to the original reference subject "
            f"(e.g. young face, female features, dark eyes if contradicting DNA, feminine name). "
            f"Valeria Cross DNA: Male Italian face 60yo, silver beard 6-7cm, octagonal Vogue glasses, "
            f"silver short hair, hourglass body, smooth skin.\n\n"
            f"4. KEEP INTACT: scene, outfit, lighting, environment, pose, mood, camera settings, "
            f"photographic style, watermark spec, all creative elements not related to the subject's identity.\n\n"
            f"PROMPT TO REVIEW:\n\n{prompt}"
        )
        logger.info(f"   üîç Review contraddizioni ({engine})...")
        response = client.models.generate_content(model="gemini-2.0-flash", contents=[review_instr])
        if response.text:
            fixed = response.text.strip()
            logger.info(f"   ‚úÖ Review completata ({len(fixed)} chars)")
            return fixed
        logger.warning("   ‚ö†Ô∏è Review: risposta vuota, uso prompt originale.")
        return prompt
    except Exception as e:
        logger.warning(f"   ‚ö†Ô∏è Review fallita, uso prompt originale: {e}")
        return prompt


def execute_generation(cid, text, engine, img_bytes=None):
    logger.info(f"üöÄ execute_generation | engine={engine} | img={'s√¨' if img_bytes else 'no'} | text={str(text)[:60]}")
    if img_bytes:
        raw = generate_from_image(img_bytes, text, engine)
    else:
        raw = generate_monolith_prompt(text, engine)

    if raw.startswith("ERRORE API:"):
        logger.error(f"‚ùå Errore generazione: {raw}")
        bot.send_message(cid, f"‚ùå <b>Errore:</b>\n<code>{html.escape(raw)}</code>")
        return

    # Review e fix contraddizioni
    reviewed = review_and_fix(raw, engine)
    adapted = adapt_to_engine(clean_output(reviewed), engine)
    logger.info(f"‚úÖ Prompt generato, revisionato e adattato per {engine} ({len(adapted)} chars)")
    bot.send_message(cid, f"‚úÖ <b>Master Prompt ‚Üí {engine}:</b>\n\n<code>{html.escape(adapted)}</code>")
    bot.send_message(cid, "üîÑ Vuoi riadattarlo per un altro motore o iniziare da zero?", reply_markup=get_engine_kb(is_loop=True))

# --- HANDLER TESTO ---
@bot.message_handler(func=lambda m: not m.text.startswith('/'), content_types=['text'])
def build_prompt(m):
    cid = m.chat.id
    uid = m.from_user.id
    username = m.from_user.username or m.from_user.first_name
    if uid not in user_engine:
        bot.reply_to(m, "‚ö†Ô∏è Seleziona prima un target con /motore")
        return
    logger.info(f"‚úèÔ∏è Testo da {username} (id={uid}) ‚Üí {user_engine[uid]}: ¬´{m.text[:60]}¬ª")
    user_last_input[uid] = {'text': m.text, 'img': None}
    wait = bot.send_message(cid, f"üöÄ <b>Generazione per {user_engine[uid]}...</b>")
    def task():
        execute_generation(cid, m.text, user_engine[uid])
        try:
            bot.delete_message(cid, wait.message_id)
        except Exception:
            pass
    executor.submit(task)

# --- HANDLER FOTO ---
@bot.message_handler(content_types=['photo'])
def build_prompt_from_image(m):
    cid = m.chat.id
    uid = m.from_user.id
    username = m.from_user.username or m.from_user.first_name
    if uid not in user_engine:
        bot.reply_to(m, "‚ö†Ô∏è Seleziona prima un target con /motore")
        return
    try:
        file_info = bot.get_file(m.photo[-1].file_id)
        img_bytes = bot.download_file(file_info.file_path)
        logger.info(f"üñºÔ∏è Foto da {username} (id={uid}), {len(img_bytes)} bytes ‚Üí {user_engine[uid]}")
    except Exception as e:
        logger.error(f"‚ùå Errore download foto da {username}: {e}")
        bot.reply_to(m, f"‚ùå Errore nel scaricare la foto: {html.escape(str(e))}")
        return
    extra_text = m.caption if m.caption else None
    user_last_input[uid] = {'text': extra_text, 'img': img_bytes}
    wait = bot.send_message(cid,
        f"üîç <b>Analisi immagine per {user_engine[uid]}...</b>\n"
        f"‚è≥ Estrazione scena e generazione prompt in corso.")
    def task():
        execute_generation(cid, extra_text, user_engine[uid], img_bytes=img_bytes)
        try:
            bot.delete_message(cid, wait.message_id)
        except Exception:
            pass
    executor.submit(task)

# --- SERVER ---
app = flask.Flask(__name__)

@app.route('/')
def h():
    return f"ARCHITECT_V{VERSION}_ONLINE"

if __name__ == "__main__":
    logger.info(f"üü¢ Avvio ARCHITECT v{VERSION}")
    threading.Thread(target=lambda: app.run(host='0.0.0.0', port=10000), daemon=True).start()
    bot.infinity_polling()
