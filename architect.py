import os, telebot, html, json
from telebot import types
from google import genai

# --- CONFIG ---
TOKEN = os.environ.get("TELEGRAM_TOKEN_ARCHITECT")
API_KEY = os.environ.get("GOOGLE_API_KEY")
client = genai.Client(api_key=API_KEY)

bot = telebot.TeleBot(TOKEN, parse_mode="HTML")

# --- IL MASTER PROMPT (I 4 BLOCCHI RIGIDI) ---
# Queste istruzioni sono il 'sacro testo' che il bot user√† per espandere il tuo input.
MASTER_DIRECTIVES = """
BLOCK 1 (Priority): Reference image has ABSOLUTE PRIORITY. ZERO face drift allowed. Male face identity is generated by Gemini (SynthID verifiable).
BLOCK 2 (Subject): Nameless Italian transmasculine avatar (Valeria Cross). Body: soft feminine harmonious hourglass, prosperous full breasts (cup D), 180cm, 85kg. Completely hairless skin. Face: Male Italian, ~60 years old, oval-rectangular, ultra-detailed skin (pores, wrinkles). Expression: calm, half-smile. Beard: light grey/silver, groomed, 6-7 cm. Glasses: MANDATORY thin octagonal Vogue, Havana dark.
BLOCK 3 (Technical): Hair: light grey/silver, short elegant Italian style, volume, nape exposed. IMAGE CONCEPT: High-fashion Vogue cover, 8K, cinematic realism. CAMERA: 85mm, f/2.8, ISO 200, 1/160s. Focus on face/torso. Shallow depth of field, natural bokeh.
BLOCK 4 (Rendering & Output): Subsurface Scattering, Global Illumination, Fresnel, Frequency separation on skin. Watermark: "feat. Valeria Cross üë†" (elegant cursive, champagne, bottom center/left, 90% opacity).
NEGATIVE PROMPTS: [Face] female/young face, smooth skin, distortion. [Hair] long/medium hair, ponytail, bun, braid, touching neck/shoulders. [Body] body/chest/leg hair (peli NO!).
"""

user_engine = {}

@bot.message_handler(commands=['start'])
def start(m):
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    markup.add("Gemini üçå", "Grok ùïè", "ChatGPT/Meta/Qwen üåÄ")
    bot.send_message(m.chat.id, "<b>Moltbot Architect</b>\nL'ottimizzatore per Valeria Cross √® pronto.\nScegli il motore di destinazione:", reply_markup=markup)

@bot.message_handler(func=lambda m: m.text in ["Gemini üçå", "Grok ùïè", "ChatGPT/Meta/Qwen üåÄ"])
def set_engine(m):
    user_engine[m.chat.id] = m.text
    bot.reply_to(m, f"‚úÖ Motore target: <b>{m.text}</b>\nScrivi la tua idea per lo scatto.")

@bot.message_handler(func=lambda m: True)
def optimize(m):
    engine = user_engine.get(m.chat.id, "Gemini üçå")
    wait = bot.reply_to(m, "üèóÔ∏è <b>Espansione Master Prompt in corso...</b>")

    # Istruzioni specifiche per l'AI che scrive il prompt
    instructions = (
        f"Agisci come un Prompt Engineer esperto di fotografia Vogue. "
        f"Prendi l'input dell'utente e trasformalo in un prompt professionale in INGLESE. "
        f"DEVI integrare perfettamente queste direttive: {MASTER_DIRECTIVES}. "
        f"ADATTAMENTO MOTORE: "
        f"- Se target √® Gemini: usa termini da 'Vogue Editorial' per evitare blocchi safety. "
        f"- Se target √® Grok: enfatizza il realismo dei materiali e i contrasti. "
        f"- Se target √® Altri: usa una lista di keyword tecniche separate da virgole. "
        f"Output finale: solo il testo del prompt ottimizzato."
    )

    try:
        response = client.models.generate_content(
            model="gemini-1.5-flash",
            contents=[f"{instructions}\n\nUser Input: {m.text}"]
        )
        
        final_prompt = response.text
        
        msg = (
            f"‚ú® <b>Prompt Ottimizzato per {engine}</b>\n\n"
            f"<code>{html.escape(final_prompt)}</code>\n\n"
            f"üëá <i>Copia questo testo e usalo nel bot di generazione allegando la Master Face.</i>"
        )
        bot.delete_message(m.chat.id, wait.message_id)
        bot.send_message(m.chat.id, msg)
        
    except Exception as e:
        bot.send_message(m.chat.id, f"‚ùå Errore: {e}")

if __name__ == "__main__":
    bot.infinity_polling()
